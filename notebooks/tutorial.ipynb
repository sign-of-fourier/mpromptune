{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48d6e340-4e21-48bd-95d8-382b9db867af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting asyncer (from -r requirements.txt (line 1))\n",
      "  Using cached asyncer-0.0.10-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting litellm==1.78.5 (from -r requirements.txt (line 2))\n",
      "  Using cached litellm-1.78.5-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting json_repair (from -r requirements.txt (line 3))\n",
      "  Using cached json_repair-0.52.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp==3.13.1 (from -r requirements.txt (line 4))\n",
      "  Using cached aiohttp-3.13.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting magicattr (from -r requirements.txt (line 5))\n",
      "  Using cached magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting gepa (from -r requirements.txt (line 6))\n",
      "  Downloading gepa-0.0.18-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from litellm==1.78.5->-r requirements.txt (line 2)) (8.1.8)\n",
      "Collecting fastuuid>=0.13.0 (from litellm==1.78.5->-r requirements.txt (line 2))\n",
      "  Using cached fastuuid-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.78.5->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.78.5->-r requirements.txt (line 2)) (6.10.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/conda/lib/python3.11/site-packages (from litellm==1.78.5->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.78.5->-r requirements.txt (line 2)) (4.23.0)\n",
      "Collecting openai>=1.99.5 (from litellm==1.78.5->-r requirements.txt (line 2))\n",
      "  Using cached openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.78.5->-r requirements.txt (line 2)) (2.11.3)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from litellm==1.78.5->-r requirements.txt (line 2)) (1.1.0)\n",
      "Collecting tiktoken>=0.7.0 (from litellm==1.78.5->-r requirements.txt (line 2))\n",
      "  Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tokenizers in /opt/conda/lib/python3.11/site-packages (from litellm==1.78.5->-r requirements.txt (line 2)) (0.21.1)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp==3.13.1->-r requirements.txt (line 4))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp==3.13.1->-r requirements.txt (line 4))\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp==3.13.1->-r requirements.txt (line 4)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp==3.13.1->-r requirements.txt (line 4)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp==3.13.1->-r requirements.txt (line 4)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp==3.13.1->-r requirements.txt (line 4)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp==3.13.1->-r requirements.txt (line 4)) (1.20.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.4.0 in /opt/conda/lib/python3.11/site-packages (from asyncer->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /opt/conda/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp==3.13.1->-r requirements.txt (line 4)) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.4.0->asyncer->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.4.0->asyncer->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.78.5->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx>=0.23.0->litellm==1.78.5->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.78.5->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm==1.78.5->-r requirements.txt (line 2)) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.78.5->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.78.5->-r requirements.txt (line 2)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.78.5->-r requirements.txt (line 2)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.78.5->-r requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.78.5->-r requirements.txt (line 2)) (1.9.0)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=1.99.5->litellm==1.78.5->-r requirements.txt (line 2))\n",
      "  Using cached jiter-0.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai>=1.99.5->litellm==1.78.5->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.0->litellm==1.78.5->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.0->litellm==1.78.5->-r requirements.txt (line 2)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.0->litellm==1.78.5->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.78.5->-r requirements.txt (line 2)) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm==1.78.5->-r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.11/site-packages (from tokenizers->litellm==1.78.5->-r requirements.txt (line 2)) (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.78.5->-r requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.78.5->-r requirements.txt (line 2)) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.78.5->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.78.5->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.78.5->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.78.5->-r requirements.txt (line 2)) (2.4.0)\n",
      "Using cached litellm-1.78.5-py3-none-any.whl (9.8 MB)\n",
      "Using cached aiohttp-3.13.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "Using cached asyncer-0.0.10-py3-none-any.whl (9.5 kB)\n",
      "Using cached json_repair-0.52.3-py3-none-any.whl (26 kB)\n",
      "Using cached magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
      "Downloading gepa-0.0.18-py3-none-any.whl (112 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached fastuuid-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (279 kB)\n",
      "Using cached openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
      "Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "Using cached jiter-0.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (359 kB)\n",
      "Installing collected packages: magicattr, json_repair, jiter, gepa, fastuuid, aiosignal, aiohappyeyeballs, tiktoken, asyncer, aiohttp, openai, litellm\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.2\n",
      "    Uninstalling aiosignal-1.3.2:\n",
      "      Successfully uninstalled aiosignal-1.3.2\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.9.5\n",
      "    Uninstalling aiohttp-3.9.5:\n",
      "      Successfully uninstalled aiohttp-3.9.5\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 asyncer-0.0.10 fastuuid-0.14.0 gepa-0.0.18 jiter-0.11.1 json_repair-0.52.3 litellm-1.78.5 magicattr-0.1.6 openai-2.6.1 tiktoken-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d98fcb0-50a0-4fbb-b454-4f4c4993964e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmpromptune\u001b[0m/  \u001b[01;34mnotebooks\u001b[0m/  requirements.txt  setup.py\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82605e35-b823-40c6-a1c7-8b7861fcdd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/custom-file-systems/efs/fs-0efe0723c8fe23def_fsap-009815092600551f0/projects/dspy\n"
     ]
    }
   ],
   "source": [
    "cd ../../dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5036f684-b55e-4118-806b-81a7ac7d7c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpromptune import qEI\n",
    "import os\n",
    "import dspy\n",
    "from dspy.datasets.gsm8k import GSM8K, gsm8k_metric\n",
    "from dspy.teleprompt import MIPROv2\n",
    "import random\n",
    "import optuna\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbce21f6-e510-4896-be70-27aca561eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM('openai/gpt-4o-mini', api_key=os.environ['OPEN_AI_KEY'])\n",
    "dspy.configure(lm=lm)\n",
    "teleprompter = MIPROv2(\n",
    "    metric=gsm8k_metric,\n",
    "    auto=\"light\",\n",
    "    num_threads=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0d9676-1b3b-474e-a656-ed806890b002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset gsm8k (/home/sagemaker-user/.cache/huggingface/datasets/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4076c652bf541f580f562fdf495f984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7473/7473 [00:00<00:00, 20726.29it/s]\n",
      "100%|██████████| 1319/1319 [00:00<00:00, 20914.83it/s]\n",
      "2025/10/26 20:25:59 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 10\n",
      "minibatch: True\n",
      "num_fewshot_candidates: 6\n",
      "num_instruct_candidates: 3\n",
      "valset size: 100\n",
      "\n",
      "2025/10/26 20:25:59 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/10/26 20:25:59 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/10/26 20:25:59 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/6\n",
      "Bootstrapping set 2/6\n",
      "Bootstrapping set 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [00:00<00:04,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:03,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [00:00<00:03,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [00:00<00:03, 10.32it/s]\n",
      "2025/10/26 20:26:00 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/10/26 20:26:00 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/26 20:26:00 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=3 instructions...\n",
      "\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Imagine you are a brilliant mathematician being tested in a high-stakes competition. You will be presented with a variety of mathematical word problems that require multi-step reasoning and strategic thinking. For each problem, analyze the provided `question` carefully and break down your reasoning step by step. After deriving a detailed explanation of how you arrived at your conclusion, provide the final `answer`. Your ability to think critically and articulate your process is crucial to your success in this competition.\n",
      "\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Imagine you are a detective solving a series of complex mathematical mysteries to crack a case that could save a community. Given the fields `question`, intricately analyze the situation and produce the fields `reasoning` and `answer`.\n",
      "\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 13 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 91.00 / 100 (91.0%): 100%|██████████| 100/100 [00:00<00:00, 217.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/26 20:26:01 INFO dspy.evaluate.evaluate: Average Metric: 91 / 100 (91.0%)\n",
      "2025/10/26 20:26:01 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 91.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/26 20:26:02 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 13 - Minibatch ==\n",
      "2025/10/26 20:26:02 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.00 / 1 (100.0%):   0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 2.00 / 2 (100.0%):   3%|▎         | 1/35 [00:00<00:00, 57.54it/s]\u001b[A\n",
      "Average Metric: 3.00 / 3 (100.0%):   6%|▌         | 2/35 [00:00<00:00, 53.11it/s]\u001b[A\n",
      "Average Metric: 4.00 / 4 (100.0%):   9%|▊         | 3/35 [00:00<00:00, 68.03it/s]\u001b[A\n",
      "Average Metric: 5.00 / 5 (100.0%):  11%|█▏        | 4/35 [00:00<00:00, 78.92it/s]\u001b[A\n",
      "Average Metric: 6.00 / 6 (100.0%):  14%|█▍        | 5/35 [00:00<00:00, 89.96it/s]\u001b[A\n",
      "Average Metric: 7.00 / 7 (100.0%):  17%|█▋        | 6/35 [00:00<00:00, 90.76it/s]\u001b[A\n",
      "Average Metric: 8.00 / 8 (100.0%):  20%|██        | 7/35 [00:00<00:00, 97.38it/s]\u001b[A\n",
      "Average Metric: 9.00 / 9 (100.0%):  23%|██▎       | 8/35 [00:00<00:00, 102.41it/s]\u001b[A\n",
      "Average Metric: 10.00 / 10 (100.0%):  26%|██▌       | 9/35 [00:00<00:00, 103.68it/s]\u001b[A\n",
      "Average Metric: 11.00 / 11 (100.0%):  29%|██▊       | 10/35 [00:00<00:00, 102.30it/s]\u001b[A\n",
      "Average Metric: 11.00 / 11 (100.0%):  31%|███▏      | 11/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 12.00 / 12 (100.0%):  31%|███▏      | 11/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 13.00 / 13 (100.0%):  34%|███▍      | 12/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 14.00 / 14 (100.0%):  37%|███▋      | 13/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 14.00 / 15 (93.3%):  40%|████      | 14/35 [00:00<00:00, 109.72it/s] \u001b[A\n",
      "Average Metric: 14.00 / 16 (87.5%):  43%|████▎     | 15/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 15.00 / 17 (88.2%):  46%|████▌     | 16/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 16.00 / 18 (88.9%):  49%|████▊     | 17/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 17.00 / 19 (89.5%):  51%|█████▏    | 18/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 18.00 / 20 (90.0%):  54%|█████▍    | 19/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 19.00 / 21 (90.5%):  57%|█████▋    | 20/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 20.00 / 22 (90.9%):  60%|██████    | 21/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 20.00 / 23 (87.0%):  63%|██████▎   | 22/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 21.00 / 24 (87.5%):  66%|██████▌   | 23/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 22.00 / 25 (88.0%):  69%|██████▊   | 24/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 23.00 / 26 (88.5%):  71%|███████▏  | 25/35 [00:00<00:00, 109.72it/s]\u001b[A\n",
      "Average Metric: 23.00 / 26 (88.5%):  74%|███████▍  | 26/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 24.00 / 27 (88.9%):  74%|███████▍  | 26/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 25.00 / 28 (89.3%):  77%|███████▋  | 27/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 26.00 / 29 (89.7%):  80%|████████  | 28/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 27.00 / 30 (90.0%):  83%|████████▎ | 29/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 28.00 / 31 (90.3%):  86%|████████▌ | 30/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 29.00 / 32 (90.6%):  89%|████████▊ | 31/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 30.00 / 33 (90.9%):  91%|█████████▏| 32/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 31.00 / 34 (91.2%):  94%|█████████▍| 33/35 [00:00<00:00, 131.21it/s]\u001b[A\n",
      "Average Metric: 32.00 / 35 (91.4%): 100%|██████████| 35/35 [00:00<00:00, 127.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/26 20:26:03 INFO dspy.evaluate.evaluate: Average Metric: 32 / 35 (91.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/26 20:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 91.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/10/26 20:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [91.43]\n",
      "2025/10/26 20:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [91.0]\n",
      "2025/10/26 20:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 91.0\n",
      "2025/10/26 20:26:03 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.00 / 35 (91.4%): 100%|██████████| 35/35 [00:30<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/26 20:26:33 INFO dspy.evaluate.evaluate: Average Metric: 32 / 35 (91.4%)\n",
      "2025/10/26 20:26:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 91.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/10/26 20:26:33 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [91.43, 91.43]\n",
      "2025/10/26 20:26:33 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [91.0]\n",
      "2025/10/26 20:26:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 91.0\n",
      "2025/10/26 20:26:33 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/10/26 20:26:33 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 91.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gsm8k = GSM8K()\n",
    "sampler= qEI.Sampler(40, 400, 4)\n",
    "optimized_program = teleprompter.compile(\n",
    "    dspy.ChainOfThought(\"question -> answer\"),\n",
    "#    MultiPredictorModule(),\n",
    "    trainset=gsm8k.train,\n",
    "    sampler=sampler,\n",
    "    n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4fa61-c6bc-491d-bff8-963d581e3f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
